// -*- mode:c++;tab-width:2;indent-tabs-mode:t;show-trailing-whitespace:t;rm-trailing-spaces:t -*-
// vi: set ts=2 noet:
//
// (c) Copyright Rosetta Commons Member Institutions.
// (c) This file is part of the Rosetta software suite and is made available under license.
// (c) The Rosetta software is developed by the contributing members of the Rosetta Commons.
// (c) For more information, see http://www.rosettacommons.org. Questions about this can be
// (c) addressed to University of Washington CoMotion, email: license@uw.edu.

/// @author Oliver Lange
/*!

last updated 3/25/10

@page archive framework README

It might make your life easier to read this in something with word-wrapping (a document editor, not a text editor)

author (of the readme): Oliver Lange; olange@u.washington.edu
author (of the code): Oliver Lange

@section one Overview

The Archive infrastructure is intended to provide a framework to easily implement iterative protocols reminiscent of genetic algorithms.
To achieve  this goal we split the N processes (e.g. N = 2048) into some dedicated control processes (e.g., MpiFileBuf, MPIArchiveJobDistributor and ArchiveManager ) and (e.g.  N-3)  worker processes that run some standard rosetta protocol of your choice (which can be controlled via cmd-line flags).
The general idea is that a pool of good structures (aka archive) is centrally managed ( by ArchiveManager / ArchiveBase and subclasses ).  When the job-queue runs low, a new batch of work (i.e., several 1000 new jobs of similar setup) will be generated by the ArchiveBase::generate_batch() method which is called by the ArchiveManager. To implement your own protocol you should extend the interface ArchiveBase and overload the virtual function generate_batch().
By creating input files and flags based on the collection of low-scoring decoys in your archive you can (hopefully) focus the optimization in the next batch in such a way which increases the likelihood to find low energy structures.
You find an example of a protocol that uses the Framework in the /protocols/abinitio/IterativeXXX classes. Most implementation is in class IterativeBase.
You will find that generate_batch() is overloaded and used to create input-files (e.g., flags, broker-setup files and input-data files) by using the structures
found in the list that can be accessed via a call to ArchiveBase::decoys().

@section two Batch

The Batch is an important helper class of the ArchiveManager / ArchiveBase classes. The class Batch defined in ArchiveManager.hh does not encapsulate
 a lot of functionality but is merely a container for information that is connected to each batch of jobs. An instance of the Batch class always corresponds to
a subdirectory 'batch_00nnn/' of the current working directory. The Batch::id() returns the running number of the batch, and Batch::dir()  returns the directory name.
Most importantly the instance of Batch is used to keep track of the status of a batch, i.e., how many of the returned decoys have already been evaluated by the Archive. Is the Batch still active ? ... etc.
This status information is stored in the file Batch::dir()/BATCH_INFO.

for testing purposes, you can run a "batch" manually outside of the Archive Framework by calling your application (without the Archive) but otherwise the same cmd-line and then adding
   -run:batches batch_000001/flags batch_000002/flags
this should now advise the JobDistributor (JD) to first generate a job-list according to your cmdline flags + the extra flags bin batch_000001/flags.
When this job-list runs empty the JD will generate a new job-list by using the cmdline flags + the flags in batch_000002/flags. The flags in batch_000001/flags
will not influence the jobs generated in the second round and vice-versa.
The same mechanism is used when the Archive is running in fully automatic mode, only that now batches are generated from the software on the fly and that
they are added two the batch-queue not via -run:batches but via MPI communication between MPIArchiveJD and ArchiveManager. (message: ADD_BATCH)

@section three MPIArchiveJobDistributor

The JobDistributor extends the MPIFileBufJobDistributor to allow communication with the ArchiveManager.

The communication utilizes messages
BATCH_SYNC, QUEUE_EMPTY, ADD_BATCH, CANCEL_BATCH and JOB_COMPLETION
and allows to
a1) queue new batches into the BatchQueue of the JobDistributor (see also option run:batches ).
   	 ADD_BATCH
a2) cancel batches that are queued but now obsolet
	 CANCEL_BATCH

b1) Tell the ArchiveManager that jobs have been completed
    JOB_COMPLETION

b2) Tell the ArchiveManager that a new batch has to be generated
    QUEUE_EMPTY

The Message BATCH_SYNC is a message sent internally within the MPIArchiveJobDistributor instances on different processors to allow updating of the
batch queue on worker nodes when the queue on the master node has changed.

The JD usually resides in the main message loop (master_go)  where it is able to receive all MPI messages that are processable by
process_message().
Since this message loop also needs to be available for communiction between JD and slave processes the notification message to the archive:
JOB_COMPLETION and QUEUE_EMPTY are handled via non-blocking communication. notify_archive() stores a 'CompletionMessage' in a message-queue
and pending msgs are forwarded to ArchiveManager whenever the low-level _notify_archive() is called (i.e., in process_message, batch_underflow()  )
This mechanisms decouples the ArchiveManager from the other communication between JD and slave nodes.

@section four ArchiveManager

The ArchiveManager (AM) organizes the communication between Archive and MPIArchiveJD. The AM knows how to start a new batch (i.e., create subdirectory )
 and to register (queue) the new batch with the JD. It manages the returning decoys so that each unique decoy is only evaluated by the archive once.
Example:
When a JOB_COMPLETION message is received for say batch 7 the output-file, say batch_00007/decoys.out, is read and 483 decoy-tags are found.
During reading the file is locked such that for the short period of reading no decoys and especially no half-decoys arrive in the file.
From BATCH_INFO the AM would know that the first 343 decoys are already known. The AM will then ask for the decoy-tags 344-483 to be read from the silent-file
and will call the  Archive::read_structure method with this silent_file object which contains only decoys 344-483.
The Archive::read_structure method is then free to decide which of these decoys to store in the archive. The AM will make sure that these decoys are never again
presented to the Archive. (it stores the information in the respective Batch object and saves the status in file in case that the program has to be restarted later).

If the AM receives a QUEUE_EMPTY message from the JD it will call ArchiveBase::generate_batch().

@section five ArchiveBase

The ArchiveBase has two important methods read_structures and generate_batch, which are called by the AM.
The ArchiveBase has access to the AM via manager().
read_structures simply adds decoys returned from the batches to the Archive by calling add_structure().
It keeps statistics about how many structures are accepted (add_structure returns boolean=true if structure was accepted).
(in the base class this is trivial, but add_structure is usually overloaded).

In the other method generate_batch it has to call

		Batch& new_batch( ArchiveBase::manager().start_new_batch() );
		ArchiveBase::manager().finalize_batch( new_batch );

	the requirement is that at least one new_batch is created during a call to generate_batch. A batch
	can be influenced between the calls of start_new_batch and finalize_batch by setting flags and adding files to
	new_batch.dir()/. it is allowed to create more than one batch by subsequent calls to start_new_batch and finalize_batch.

	(see example code in IterativeBase.cc )

the last responsibility of the ArchiveBase is to keep some statistics about acceptance vs. proposed decoys.
current_acceptance_ratio() yields the ratio accepted/proposed computed as running as average over the last min_structures_for_acceptance_statistics_

@section six EvaluatedArchive

This class extends ArchiveBase by overloading add_structure() such that only structures with lower scores are accepted into the archive.

Scoring occurs in the following steps:
1) a silent-struct is generated which contains various columns with score-components and extra-columns added by PoseEvaluators that are found
evaluators_
2) any real-valued column can be added to a weighted sum as controlled by the WeightMap select_weights_.

for instance this map could contain { "score", 1.0 }, { "rms", 0.0 }, {"rdc", 1.0 } and now would add columns score and rdc with equal weights.
If the scorefxn responsible for column score already contained a non-zero weight for rdc you would account for rdc twice!

Things became a bit complicated because 'rescoring' decoys on the master-node is too expensive on large-scale runs on the BlueGene machine. The expensive
step is actually not the scoring but the "fill_pose" method that creates a pose from a silent-struct.
Instead the EvaluatedArchive will not run step (1) and proceeds directly to step (2)  when add_structure is called. For the IterativeXXX implementation the
WeightMap contains {"score_final", 1.0 } and the generate_batch() function of IterativeBase makes sure to include a final PoseEvaluator that creates a score_final
column in the output file. This is necessary in cases when you want to select decoys on a different score than the score used for sampling. In my original application
that was usually the case. I used a high weight on constraints in selection but low weights in sampling. Lool at IterativeBase::gen_evaluation_output() to see how
this score_final column is setup.

@section seven IterativeBase

This class extends EvaluatedArchive to implement a high-level protocol.


